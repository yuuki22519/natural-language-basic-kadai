{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SNobRxbDDoQ",
        "outputId": "9babde68-8e87-4168-b4ee-6dd107d8aa4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aKtJjMBMBZ_2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.aozora.gr.jp/cards/000148/files/2371_13943.html'\n",
        "response = request.urlopen(url)\n",
        "soup = BeautifulSoup(response)\n",
        "response.close()\n",
        "# print(soup)\n",
        "\n",
        "# タグ削除\n",
        "main_text = soup.find('div', class_='main_text') # 本文のみ\n",
        "# print(main_text)\n",
        "\n",
        "tag_to_delete = main_text.find_all(['rt', 'rp'])\n",
        "for tag in tag_to_delete:\n",
        "    tag.decompose()\n",
        "# print(main_text)\n",
        "\n",
        "main_text = main_text.get_text()\n",
        "# print(main_text)\n",
        "\n",
        "main_text = re.sub(r\"[\\u3000 \\n \\r]\", \"\", main_text)\n",
        "print(main_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRElZ4vBiOF",
        "outputId": "696796ab-4381-4f4b-b3c9-a59c9e044f8c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "近頃は大分方々の雑誌から談話をしろしろと責められて、頭ががらん胴になったから、当分品切れの看板でも懸けたいくらいに思っています。現に今日も一軒断わりました。向後日本の文壇はどう変化するかなどという大問題はなかなか分りにくい。いわんや二三日前まで『文学評論』の訂正をしていて、頭が痺れたように疲れているから、早速に分別も浮びません。それに似寄った事をせんだってごく簡略に『秀才文壇』の人に話してしまった。あいにくこの方面も種切れです。が、まあせっかくだから――いつおいでになっても、私の談話が御役に立った試がないようだから――つまらん事でも責任逃れに話しましょう。私が小説を書き出したのは、何年前からか確と覚えてもいないが、けっして古くはない。見方によればごく近頃であると云ってもよろしい。しかるに我が文壇の潮流は非常に急なもので、私よりあとから、小説家として、世にあらわれ、また一般から作家として認められたものが大分ある。今も続々出つつあるように思われる。私は多忙な身だから、ほかの人の作を一々通読する暇がない。たてこんで来ると、つい読み損って、それぎりにする事もあるが、できるだけは参考のため、研究のため、あるいは興味のため、目を通して見る。ところが年一年と日を経るに従って、みんな面白い。だんだん老熟の手腕が短篇のうちに行き渡って来たように思われる。妙な比較をするようだけれども近来日本の雑誌に出る創作物の価値は、英国の通俗雑誌に掲載せられる短篇ものよりも、ずっと程度の高いものと自分は信じている。だから日本の文壇は前途多望、大いに楽観すべき現象に充ちていると思います。そこで今云った通り新参の私のあとから、すでに四五人の新進作家が出るくらいだから、そのあとからもまた出て来るに違ない。現に出つつあるんでしょう。また未来に出ようとして待ち構えている人も定めて多い事だろうと思います。して見るとこれらの四五の新進作家――必ずしもこれらの人に限る必要はないが――はまた新らしい競争者を得らるる事と信ずる。この競争者の出かたである。出かたに二た通りある。一つは自分の縄張うちへ這入って来て、似寄った武器と、同種の兵法剣術で競争をやる。元来競争となるとたいていの場合は同種同類に限るようです。同種同類でないと、本当の比較ができないからでもあるし、ひとつ、あいつを乗り越してやろうと云う時は、裏道があってもかえって気がつかないで、やっぱり当の敵の向うに見える本街道をあとを慕って走け出すのが心理的に普通な状態であります。すると同圏内で競争が起ります。この競争の刺激によって、作物がだんだん深さを増して来る。種類が同じだから深さ以外に競争のしようがないのであります。今一つの競争は圏外に新手が出る事であります。これから新たに文壇に顔を出そうと機を覗っている人、もしくはすでに打って出た人のうちで、今までのものとは径路を同じゅうする事を好まない事がないとも限らない。これは今までの作物に飽き足らぬか、もしくは、おれはおれだから是非一派を立てて見せると自己の特色に自信をおくか、または世間の注意を惹くには何か異様な武者ぶりを見せないと効力が少ないとか、いろいろの動機から起るだろうが、要するに模擬者でもなければ、同圏内の競争者でもない。すなわち圏外の敵である。この種の競争者が出て来ると、文壇の刺激は種類と種類の間に起る。種類が多ければ多いほど文壇は多趣多様になって、互に競り合が始まる訳である。もしこの二種類の競争すなわち圏の内外に互に競争が同時に起るとすると、向後吾人の受くる作物は、この両個の刺激からして、在来のはますます在来の方向で深く発達したもの、新興のは新興の領分で出来得る限りを開拓して変化を添えるようなものになる。もっとも圏外の競争が烈しくなると、圏内の競争は比較的穏かになる。また圏内の競争が烈しい時は、比較的圏外が平和である。圏内の競争が烈しくなるか、圏外の競争が烈しくなるか、どちらに傾くかは、読書界の傾向で大部きめられる問題であります。もし読書界が把住性が強くって、在来の作物からなお或物を予期しつつある間は、圏内の競争の方が烈しい。また読書界が推移性に支配されつつあって、何か新発展を希望する場合には圏外に優勢なものがあらわれ勝になる。もし読書界が両分されて半々になるときは圏内圏外共に相応の競争があって、相応の読者を有する訳になります。私は実際の作物にあたって、とかくの評をする事をしない。したがって向後の読書界がどういう作物をどう歓迎するかも云えない。ただ形式ばかりの話ではなはだつまらないが、各自この形式を実地にあてはめて見たらいろいろな鑑定ができるだろうと思う。競争はとうてい免がれない。また競争がなければ作物は進歩しない。今日の作物がこれまで進歩したのは作家の天分にもよるだろうけれども大部分は競争の賜物だろうと考えます。英国の政党が立憲政治の始まった時から二派に分れている。あれは偶然のような必然のような歴史を有しているが相互に相互を研究し啓発すると云う大原則を政治上にうまく応用したものであります。もっともこれは圏外の競争の意味である。そうして、日本の作物が輓近四五年間に大変進歩したのは、全くこの圏外の競争心の結果ではなかろうかと思われる。圏外の競争は一方において反撥を意味している。けれどもその反撥の裏面には同化の芽を含んでいる。反撥すると云う事がすでに対者を知らねばできない事になる。対者を知るためには一種の研究をしなければならない。その研究をして反撥し合っているうちに対者の立場やら長所やらを自然と認めなければならないようになる。その時にある程度の同化はどうしても起るべきはずである。文壇がこの期に達した時には混戦の状態に陥いる。混戦の状態に陥ると一騎打の競争よりほかになくなってしまう。日本の文壇がすでに混戦時代に達したか、あるいは達せんとしつつあるかは読者の判断に任せておきます。いわゆる文明社界に住む人の特色は何だと纏めて云って御覧なさい。私にはこう見える。いわゆる文明社会に住む人は誰を捉まえてもたいてい同じである。教育の程度、知識の範囲、その他いろいろの資格において、ほぼ似通っている。だから誰かれの差別はない。皆同じである。が同時に一方から見ると文明社会に住む人ほど個人主義なものはない。どこまでも我は我で通している。人の威圧やら束縛をけっして肯わない。信仰の点においても、趣味の点においても、あらゆる意見においても、かつて雷同附和の必要を認めない。また阿諛迎合の必要を認めない。してみるといわゆる文明社界に生息している人間ほど平等的なるものはなく、また個人的なるものはない。すでに平等的である以上は圏を画して圏内圏外の別を説く必要はない。英国の二大政党のごときは単に採決に便宜なる約束的の団隊と見傚して差支ない。またすでに個人的である以上はどこまでも自己の特色を自己の特色として保存する必要がある。文壇の諸公をいわゆる文明社会に住む人と見傚せば、勢いこの性質を具していなければならない。人間としてこの性質を帯びている以上は作物の上にも早晩この性質を発揮するのが天下の趨勢である。いわゆる混戦時代が始まって、彼我相通じ、しかも彼我相守り、自己の特色を失わざると共に、同圏異圏の臭味を帯びざるようになった暁が、わが文壇の歴史に一段落を告げる時ではなかろうかと思います。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-1788db5e99bd>:3: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  soup = BeautifulSoup(response)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwordsの取得\n",
        "url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
        "response = request.urlopen(url)\n",
        "stopwords_text = BeautifulSoup(response)\n",
        "response.close()\n",
        "\n",
        "stopwords_text = stopwords_text.text\n",
        "# print(stopwords_text)\n",
        "\n",
        "stopwords_list = stopwords_text.split('\\r\\n')\n",
        "stopwords_list = [word for word in stopwords_list if word]\n",
        "# print(stopwords_list)\n",
        "\n",
        "first_text_list = ['近頃', 'は', '大分', '方々', 'の', '雑誌', 'から', '談話', 'を', 'しろ', 'しろ', 'と', '責め', 'られて', '、', '頭', 'が', 'がらん', '胴', 'に', 'なっ', 'た', 'から', '、', '当分', '品', '切れ', 'の', '看板', 'でも', '懸け', 'たい', 'くらい', 'に', '思っ', 'て', 'い', 'ます', '。']\n",
        "result_text_list = list()\n",
        "for a in first_text_list:\n",
        "    if a not in stopwords_list:\n",
        "        result_text_list.append(a)\n",
        "\n",
        "print(result_text_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IftfmZ9pCb_C",
        "outputId": "83f3ff2c-811c-42b6-89be-0d7fc811093a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['近頃', 'は', '大分', '方々', 'の', '雑誌', '談話', 'を', 'しろ', 'しろ', 'と', '責め', 'られて', '、', '頭', 'が', 'がらん', '胴', 'に', 'なっ', 'た', '、', '当分', '切れ', 'の', '看板', 'でも', '懸け', 'たい', 'くらい', 'に', '思っ', 'て', 'い', 'ます', '。']\n"
          ]
        }
      ]
    }
  ]
}